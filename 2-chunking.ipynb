{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cf782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "def chunk_by_paragraphs(text: str, max_chunk_size: int = 1000) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks by paragraphs.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "        \n",
    "    Returns:\n",
    "        List of text chunks\n",
    "    \"\"\"\n",
    "    # Split by double newlines (paragraphs)\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        para = para.strip()\n",
    "        if not para:\n",
    "            continue\n",
    "            \n",
    "        para_length = len(para)\n",
    "        \n",
    "        # If single paragraph is too large, split it by sentences\n",
    "        if para_length > max_chunk_size:\n",
    "            if current_chunk:\n",
    "                chunks.append('\\n\\n'.join(current_chunk))\n",
    "                current_chunk = []\n",
    "                current_length = 0\n",
    "            \n",
    "            # Split large paragraph into sentences\n",
    "            sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
    "            temp_chunk = []\n",
    "            temp_length = 0\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                if temp_length + len(sentence) > max_chunk_size and temp_chunk:\n",
    "                    chunks.append(' '.join(temp_chunk))\n",
    "                    temp_chunk = [sentence]\n",
    "                    temp_length = len(sentence)\n",
    "                else:\n",
    "                    temp_chunk.append(sentence)\n",
    "                    temp_length += len(sentence)\n",
    "            \n",
    "            if temp_chunk:\n",
    "                chunks.append(' '.join(temp_chunk))\n",
    "        \n",
    "        # If adding paragraph exceeds max size, save current chunk\n",
    "        elif current_length + para_length > max_chunk_size and current_chunk:\n",
    "            chunks.append('\\n\\n'.join(current_chunk))\n",
    "            current_chunk = [para]\n",
    "            current_length = para_length\n",
    "        else:\n",
    "            current_chunk.append(para)\n",
    "            current_length += para_length\n",
    "    \n",
    "    # Add remaining chunk\n",
    "    if current_chunk:\n",
    "        chunks.append('\\n\\n'.join(current_chunk))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def process_json_file(json_path: Path, max_chunk_size: int = 1000) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Process a single JSON file and create chunks.\n",
    "    \n",
    "    Args:\n",
    "        json_path: Path to the JSON file\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "        \n",
    "    Returns:\n",
    "        List of chunk dictionaries\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    text = data.get('text', '')\n",
    "    metadata = data.get('metadata', {})\n",
    "    \n",
    "    # Create chunks\n",
    "    chunks = chunk_by_paragraphs(text, max_chunk_size)\n",
    "    \n",
    "    # Add metadata to each chunk\n",
    "    result = []\n",
    "    for i, chunk_text in enumerate(chunks):\n",
    "        result.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk_text,\n",
    "            \"char_count\": len(chunk_text),\n",
    "            \"word_count\": len(chunk_text.split()),\n",
    "            \"source_file\": metadata.get('source_file', ''),\n",
    "            \"source_path\": metadata.get('source_path', '')\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def save_chunks_jsonl(chunks: List[Dict], output_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save chunks to JSONL file (one JSON object per line).\n",
    "    \n",
    "    Args:\n",
    "        chunks: List of chunk dictionaries\n",
    "        output_path: Path for output JSONL file\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for chunk in chunks:\n",
    "            json.dump(chunk, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "def process_all_json_files(\n",
    "    input_dir: str = r\"C:\\Users\\yigit\\Desktop\\Enterprises\\polcon\\text\",\n",
    "    output_dir: str = r\"C:\\Users\\yigit\\Desktop\\Enterprises\\polcon\\basic-chunks\",\n",
    "    max_chunk_size: int = 1000\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Process all JSON files and create chunked JSONL files.\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing JSON files\n",
    "        output_dir: Directory to save chunked JSONL files\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = list(input_path.glob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(json_files)} JSON files to process\\n\")\n",
    "    \n",
    "    total_chunks = 0\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            print(f\"Processing: {json_file.name}...\", end=\" \")\n",
    "            \n",
    "            # Create chunks\n",
    "            chunks = process_json_file(json_file, max_chunk_size)\n",
    "            \n",
    "            # Save as JSONL\n",
    "            output_file = output_path / f\"{json_file.stem}_chunks.jsonl\"\n",
    "            save_chunks_jsonl(chunks, output_file)\n",
    "            \n",
    "            total_chunks += len(chunks)\n",
    "            print(f\"✓ Created {len(chunks)} chunks → {output_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\nProcessing complete!\")\n",
    "    print(f\"Total chunks created: {total_chunks}\")\n",
    "    print(f\"Files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525b16e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 89 JSON files to process\n",
      "\n",
      "Processing: 1) Temel kavramlar önyargı, kalıpyargı ve ayrımcılık.json... ✓ Created 34 chunks → 1) Temel kavramlar önyargı, kalıpyargı ve ayrımcılık_chunks.jsonl\n",
      "Processing: 10) TÜRKİYE’DE ÖRGÜTLENME ÖZGÜRLÜĞÜNÜN GENEL GÖRÜNÜMÜ-II .json... ✓ Created 193 chunks → 10) TÜRKİYE’DE ÖRGÜTLENME ÖZGÜRLÜĞÜNÜN GENEL GÖRÜNÜMÜ-II _chunks.jsonl\n",
      "Processing: 11) Yurttaslik_Alani_Bilgi_Notu_1.json... ✓ Created 31 chunks → 11) Yurttaslik_Alani_Bilgi_Notu_1_chunks.jsonl\n",
      "Processing: 12) TERÖRLE MÜCADELEYİ ARAÇSALLAŞTIRMAK.json... ✓ Created 107 chunks → 12) TERÖRLE MÜCADELEYİ ARAÇSALLAŞTIRMAK_chunks.jsonl\n",
      "Processing: 13) PROTESTO HAKKINI KORU.json... ✓ Created 264 chunks → 13) PROTESTO HAKKINI KORU_chunks.jsonl\n",
      "Processing: 14) KomploTeorileri_AR_23.03.23_web.json... ✓ Created 89 chunks → 14) KomploTeorileri_AR_23.03.23_web_chunks.jsonl\n",
      "Processing: 15) Feminist_Hareketin_Gundemleri_.json... ✓ Created 54 chunks → 15) Feminist_Hareketin_Gundemleri__chunks.jsonl\n",
      "Processing: 16) Sivil Toplum Kuruluşlarının Devlet Tarafından Finansmanı Üzerine Bir Tartışma.json... ✓ Created 41 chunks → 16) Sivil Toplum Kuruluşlarının Devlet Tarafından Finansmanı Üzerine Bir Tartışma_chunks.jsonl\n",
      "Processing: 17) Gençlik Politikalarında Karşılaştırmalı Bir Değerlendirme-Türkiye ve Finlandiya Örneği.json... ✓ Created 86 chunks → 17) Gençlik Politikalarında Karşılaştırmalı Bir Değerlendirme-Türkiye ve Finlandiya Örneği_chunks.jsonl\n",
      "Processing: 18) Avrupa Konseyi Politik Karar Alma Süreçlerine Sivil Katılım Rehberi Çevirisi.json... ✓ Created 38 chunks → 18) Avrupa Konseyi Politik Karar Alma Süreçlerine Sivil Katılım Rehberi Çevirisi_chunks.jsonl\n",
      "Processing: 19) Kampüsten Öğrenci Toplulukları .json... ✓ Created 455 chunks → 19) Kampüsten Öğrenci Toplulukları _chunks.jsonl\n",
      "Processing: 2) Ayrımcılık ve medya.json... ✓ Created 45 chunks → 2) Ayrımcılık ve medya_chunks.jsonl\n",
      "Processing: 20) Gençler Ne(ler) İstiyor_ .json... ✓ Created 30 chunks → 20) Gençler Ne(ler) İstiyor_ _chunks.jsonl\n",
      "Processing: 21) Türkiye’de Gençlik ve Siyaset_ Gelecek İçin Nasıl Bir Katılım_ .json... ✓ Created 72 chunks → 21) Türkiye’de Gençlik ve Siyaset_ Gelecek İçin Nasıl Bir Katılım_ _chunks.jsonl\n",
      "Processing: 22) Gençlik Araştırmaları Dergisi 13.sayı.json... ✓ Created 624 chunks → 22) Gençlik Araştırmaları Dergisi 13.sayı_chunks.jsonl\n",
      "Processing: 23) Türkiye_de Gençlik Miti 1980 Sonrası Türkiye Gençliği İletişim Yayınları.json... ✓ Created 485 chunks → 23) Türkiye_de Gençlik Miti 1980 Sonrası Türkiye Gençliği İletişim Yayınları_chunks.jsonl\n",
      "Processing: 24) Türkiye’nin Gençliği Araştırması Raporu -SODEV- .json... ✓ Created 9 chunks → 24) Türkiye’nin Gençliği Araştırması Raporu -SODEV- _chunks.jsonl\n",
      "Processing: 25) Türkiye’de Gençlerin Güvencesizliği_ Çalışma, Geçim ve Yaşam Algısı.json... ✓ Created 171 chunks → 25) Türkiye’de Gençlerin Güvencesizliği_ Çalışma, Geçim ve Yaşam Algısı_chunks.jsonl\n",
      "Processing: 26) Toplumun Boğaziçi Üniversitesi Olaylarına Bakışı.json... ✓ Created 36 chunks → 26) Toplumun Boğaziçi Üniversitesi Olaylarına Bakışı_chunks.jsonl\n",
      "Processing: 27) Kürt Gençler’20 Benzerlikler Farklar Değişimler.json... ✓ Created 125 chunks → 27) Kürt Gençler’20 Benzerlikler Farklar Değişimler_chunks.jsonl\n",
      "Processing: 28) NEET Gençler Araştırması – NEET Gençlerin İnsan Onuruna Yaraşır Yaşam Sürme Hakkına Erişimi.json... ✓ Created 281 chunks → 28) NEET Gençler Araştırması – NEET Gençlerin İnsan Onuruna Yaraşır Yaşam Sürme Hakkına Erişimi_chunks.jsonl\n",
      "Processing: 29) TGSP Türkiye’nin Gençleri Araştırması.pdf.json... ✓ Created 79 chunks → 29) TGSP Türkiye’nin Gençleri Araştırması.pdf_chunks.jsonl\n",
      "Processing: 3) Toplumsal Cinsiyete Dayalı Ayrımcılık.json... ✓ Created 33 chunks → 3) Toplumsal Cinsiyete Dayalı Ayrımcılık_chunks.jsonl\n",
      "Processing: 30) TOG Gençlik Çalışmasının Toplumsal Katılıma Etkisi Araştırması.json... ✓ Created 182 chunks → 30) TOG Gençlik Çalışmasının Toplumsal Katılıma Etkisi Araştırması_chunks.jsonl\n",
      "Processing: 31) Türkiye’de Gençlerin İyi Olma Hali Saha Araştırması Bulguları- HABİTAT- .json... ✓ Created 230 chunks → 31) Türkiye’de Gençlerin İyi Olma Hali Saha Araştırması Bulguları- HABİTAT- _chunks.jsonl\n",
      "Processing: 32) Türkiye Gençlik Araştırması 2021.json... ✓ Created 833 chunks → 32) Türkiye Gençlik Araştırması 2021_chunks.jsonl\n",
      "Processing: 33) Türkiye’nin Gençliği Araştırması Raporu -SODEV- 2020.json... ✓ Created 10 chunks → 33) Türkiye’nin Gençliği Araştırması Raporu -SODEV- 2020_chunks.jsonl\n",
      "Processing: 34)Uluslararası Af Örgütü.json... ✓ Created 227 chunks → 34)Uluslararası Af Örgütü_chunks.jsonl\n",
      "Processing: 37) Perspectives on Youth Participation.json... ✓ Created 58 chunks → 37) Perspectives on Youth Participation_chunks.jsonl\n",
      "Processing: 38) Young people’s right to assemble peacefully.json... ✓ Created 84 chunks → 38) Young people’s right to assemble peacefully_chunks.jsonl\n",
      "Processing: 39) Shrinking democratic civic space for youth.json... ✓ Created 79 chunks → 39) Shrinking democratic civic space for youth_chunks.jsonl\n",
      "Processing: 4) Uluslararası Af Örgütü Raporu 2021-2022 Avrupa ve Orta Asya Değerlendirmesi(sayfa 46-54).json... ✓ Created 35 chunks → 4) Uluslararası Af Örgütü Raporu 2021-2022 Avrupa ve Orta Asya Değerlendirmesi(sayfa 46-54)_chunks.jsonl\n",
      "Processing: 40) Türkiye’de Genç İntiharları.json... ✓ Created 170 chunks → 40) Türkiye’de Genç İntiharları_chunks.jsonl\n",
      "Processing: 41) Türkiye’de Genç İntiharları Politika Önerileri.json... ✓ Created 11 chunks → 41) Türkiye’de Genç İntiharları Politika Önerileri_chunks.jsonl\n",
      "Processing: 42) Türkiye_de ifade ve medya özgürlüğü ve insan hakları savunucuları ile sivil toplumun durumu hakkındaki memorandum.json... ✓ Created 68 chunks → 42) Türkiye_de ifade ve medya özgürlüğü ve insan hakları savunucuları ile sivil toplumun durumu hakkındaki memorandum_chunks.jsonl\n",
      "Processing: 43) Türkiye’deki Gençlik Örgütlerinin İhtiyaç Analizi Raporu 2025.json... ✓ Created 169 chunks → 43) Türkiye’deki Gençlik Örgütlerinin İhtiyaç Analizi Raporu 2025_chunks.jsonl\n",
      "Processing: 44)Toplumsal Değerler ve Gençlik Araştırma Raporu.json... ✓ Created 56 chunks → 44)Toplumsal Değerler ve Gençlik Araştırma Raporu_chunks.jsonl\n",
      "Processing: 45) Gençlerin Politik Tercihleri Araştırması.json... ✓ Created 187 chunks → 45) Gençlerin Politik Tercihleri Araştırması_chunks.jsonl\n",
      "Processing: 46)Gençlik Araştırmaları Dergisi 35.sayı.json... ✓ Created 361 chunks → 46)Gençlik Araştırmaları Dergisi 35.sayı_chunks.jsonl\n",
      "Processing: 47)Gençler için nasıl bir kent_.json... ✓ Created 79 chunks → 29) TGSP Türkiye’nin Gençleri Araştırması.pdf_chunks.jsonl\n",
      "Processing: 3) Toplumsal Cinsiyete Dayalı Ayrımcılık.json... ✓ Created 33 chunks → 3) Toplumsal Cinsiyete Dayalı Ayrımcılık_chunks.jsonl\n",
      "Processing: 30) TOG Gençlik Çalışmasının Toplumsal Katılıma Etkisi Araştırması.json... ✓ Created 182 chunks → 30) TOG Gençlik Çalışmasının Toplumsal Katılıma Etkisi Araştırması_chunks.jsonl\n",
      "Processing: 31) Türkiye’de Gençlerin İyi Olma Hali Saha Araştırması Bulguları- HABİTAT- .json... ✓ Created 230 chunks → 31) Türkiye’de Gençlerin İyi Olma Hali Saha Araştırması Bulguları- HABİTAT- _chunks.jsonl\n",
      "Processing: 32) Türkiye Gençlik Araştırması 2021.json... ✓ Created 833 chunks → 32) Türkiye Gençlik Araştırması 2021_chunks.jsonl\n",
      "Processing: 33) Türkiye’nin Gençliği Araştırması Raporu -SODEV- 2020.json... ✓ Created 10 chunks → 33) Türkiye’nin Gençliği Araştırması Raporu -SODEV- 2020_chunks.jsonl\n",
      "Processing: 34)Uluslararası Af Örgütü.json... ✓ Created 227 chunks → 34)Uluslararası Af Örgütü_chunks.jsonl\n",
      "Processing: 37) Perspectives on Youth Participation.json... ✓ Created 58 chunks → 37) Perspectives on Youth Participation_chunks.jsonl\n",
      "Processing: 38) Young people’s right to assemble peacefully.json... ✓ Created 84 chunks → 38) Young people’s right to assemble peacefully_chunks.jsonl\n",
      "Processing: 39) Shrinking democratic civic space for youth.json... ✓ Created 79 chunks → 39) Shrinking democratic civic space for youth_chunks.jsonl\n",
      "Processing: 4) Uluslararası Af Örgütü Raporu 2021-2022 Avrupa ve Orta Asya Değerlendirmesi(sayfa 46-54).json... ✓ Created 35 chunks → 4) Uluslararası Af Örgütü Raporu 2021-2022 Avrupa ve Orta Asya Değerlendirmesi(sayfa 46-54)_chunks.jsonl\n",
      "Processing: 40) Türkiye’de Genç İntiharları.json... ✓ Created 170 chunks → 40) Türkiye’de Genç İntiharları_chunks.jsonl\n",
      "Processing: 41) Türkiye’de Genç İntiharları Politika Önerileri.json... ✓ Created 11 chunks → 41) Türkiye’de Genç İntiharları Politika Önerileri_chunks.jsonl\n",
      "Processing: 42) Türkiye_de ifade ve medya özgürlüğü ve insan hakları savunucuları ile sivil toplumun durumu hakkındaki memorandum.json... ✓ Created 68 chunks → 42) Türkiye_de ifade ve medya özgürlüğü ve insan hakları savunucuları ile sivil toplumun durumu hakkındaki memorandum_chunks.jsonl\n",
      "Processing: 43) Türkiye’deki Gençlik Örgütlerinin İhtiyaç Analizi Raporu 2025.json... ✓ Created 169 chunks → 43) Türkiye’deki Gençlik Örgütlerinin İhtiyaç Analizi Raporu 2025_chunks.jsonl\n",
      "Processing: 44)Toplumsal Değerler ve Gençlik Araştırma Raporu.json... ✓ Created 56 chunks → 44)Toplumsal Değerler ve Gençlik Araştırma Raporu_chunks.jsonl\n",
      "Processing: 45) Gençlerin Politik Tercihleri Araştırması.json... ✓ Created 187 chunks → 45) Gençlerin Politik Tercihleri Araştırması_chunks.jsonl\n",
      "Processing: 46)Gençlik Araştırmaları Dergisi 35.sayı.json... ✓ Created 361 chunks → 46)Gençlik Araştırmaları Dergisi 35.sayı_chunks.jsonl\n",
      "Processing: 47)Gençler için nasıl bir kent_.json... ✓ Created 40 chunks → 47)Gençler için nasıl bir kent__chunks.jsonl\n",
      "Processing: 48) TGSP Gençlerin Gönüllülük Algısı.json... ✓ Created 93 chunks → 48) TGSP Gençlerin Gönüllülük Algısı_chunks.jsonl\n",
      "Processing: 49) Yerel Yonetimlere Iliskin PolitikaBelgesi.json... ✓ Created 26 chunks → 49) Yerel Yonetimlere Iliskin PolitikaBelgesi_chunks.jsonl\n",
      "Processing: 5) Paralel Kariyer Arayışının Nedenleri Isparta’da Faaliyet Gösteren STK’larda Bir Araştırma.json... ✓ Created 37 chunks → 5) Paralel Kariyer Arayışının Nedenleri Isparta’da Faaliyet Gösteren STK’larda Bir Araştırma_chunks.jsonl\n",
      "Processing: 50) Milliyetçiliğin Dönüşümü ve Genç Yüzleri.json... ✓ Created 273 chunks → 50) Milliyetçiliğin Dönüşümü ve Genç Yüzleri_chunks.jsonl\n",
      "Processing: 51)Gençlik Araştırması - Türkiye 2024.json... ✓ Created 121 chunks → 51)Gençlik Araştırması - Türkiye 2024_chunks.jsonl\n",
      "Processing: 52)CORE Gençlerin Seçimi.json... ✓ Created 86 chunks → 52)CORE Gençlerin Seçimi_chunks.jsonl\n",
      "Processing: 53) Gençlerin Güçlendirilmesine Yönelik Harcamaları İzleme Kılavuzu.json... ✓ Created 4 chunks → 53) Gençlerin Güçlendirilmesine Yönelik Harcamaları İzleme Kılavuzu_chunks.jsonl\n",
      "Processing: 54) Gençlerin Siyasi Katılımı - Şebeke 1.json... ✓ Created 495 chunks → 54) Gençlerin Siyasi Katılımı - Şebeke 1_chunks.jsonl\n",
      "Processing: 55) Türkiye_de Gençlerin Katılımı - Şebeke.json... ✓ Created 174 chunks → 55) Türkiye_de Gençlerin Katılımı - Şebeke_chunks.jsonl\n",
      "Processing: 56) COVID-19 Pandemisi Sürecinde Gençlerin İyilik Halinin Belirlenmesi Araştırması.json... ✓ Created 413 chunks → 56) COVID-19 Pandemisi Sürecinde Gençlerin İyilik Halinin Belirlenmesi Araştırması_chunks.jsonl\n",
      "Processing: 57) KONDA - Hafıza Merkezi Gençlerin İnsan Hakları Algısı_.json... ✓ Created 221 chunks → 57) KONDA - Hafıza Merkezi Gençlerin İnsan Hakları Algısı__chunks.jsonl\n",
      "Processing: 58) Türkiye_de Gençlik Çalışması ve Politikası.json... ✓ Created 40 chunks → 47)Gençler için nasıl bir kent__chunks.jsonl\n",
      "Processing: 48) TGSP Gençlerin Gönüllülük Algısı.json... ✓ Created 93 chunks → 48) TGSP Gençlerin Gönüllülük Algısı_chunks.jsonl\n",
      "Processing: 49) Yerel Yonetimlere Iliskin PolitikaBelgesi.json... ✓ Created 26 chunks → 49) Yerel Yonetimlere Iliskin PolitikaBelgesi_chunks.jsonl\n",
      "Processing: 5) Paralel Kariyer Arayışının Nedenleri Isparta’da Faaliyet Gösteren STK’larda Bir Araştırma.json... ✓ Created 37 chunks → 5) Paralel Kariyer Arayışının Nedenleri Isparta’da Faaliyet Gösteren STK’larda Bir Araştırma_chunks.jsonl\n",
      "Processing: 50) Milliyetçiliğin Dönüşümü ve Genç Yüzleri.json... ✓ Created 273 chunks → 50) Milliyetçiliğin Dönüşümü ve Genç Yüzleri_chunks.jsonl\n",
      "Processing: 51)Gençlik Araştırması - Türkiye 2024.json... ✓ Created 121 chunks → 51)Gençlik Araştırması - Türkiye 2024_chunks.jsonl\n",
      "Processing: 52)CORE Gençlerin Seçimi.json... ✓ Created 86 chunks → 52)CORE Gençlerin Seçimi_chunks.jsonl\n",
      "Processing: 53) Gençlerin Güçlendirilmesine Yönelik Harcamaları İzleme Kılavuzu.json... ✓ Created 4 chunks → 53) Gençlerin Güçlendirilmesine Yönelik Harcamaları İzleme Kılavuzu_chunks.jsonl\n",
      "Processing: 54) Gençlerin Siyasi Katılımı - Şebeke 1.json... ✓ Created 495 chunks → 54) Gençlerin Siyasi Katılımı - Şebeke 1_chunks.jsonl\n",
      "Processing: 55) Türkiye_de Gençlerin Katılımı - Şebeke.json... ✓ Created 174 chunks → 55) Türkiye_de Gençlerin Katılımı - Şebeke_chunks.jsonl\n",
      "Processing: 56) COVID-19 Pandemisi Sürecinde Gençlerin İyilik Halinin Belirlenmesi Araştırması.json... ✓ Created 413 chunks → 56) COVID-19 Pandemisi Sürecinde Gençlerin İyilik Halinin Belirlenmesi Araştırması_chunks.jsonl\n",
      "Processing: 57) KONDA - Hafıza Merkezi Gençlerin İnsan Hakları Algısı_.json... ✓ Created 221 chunks → 57) KONDA - Hafıza Merkezi Gençlerin İnsan Hakları Algısı__chunks.jsonl\n",
      "Processing: 58) Türkiye_de Gençlik Çalışması ve Politikası.json... ✓ Created 1146 chunks → 58) Türkiye_de Gençlik Çalışması ve Politikası_chunks.jsonl\n",
      "Processing: 59) LGBTİ gençler gençlik merkezlerinde ne istiyor_.json... ✓ Created 35 chunks → 59) LGBTİ gençler gençlik merkezlerinde ne istiyor__chunks.jsonl\n",
      "Processing: 6) Sivil Toplum Örgütlerinde Profesyonel ve Gönüllü Çalışma İlişkileri Tehditler Ve Fırsatlar.json... ✓ Created 43 chunks → 6) Sivil Toplum Örgütlerinde Profesyonel ve Gönüllü Çalışma İlişkileri Tehditler Ve Fırsatlar_chunks.jsonl\n",
      "Processing: 60) Genç Kadınların Karar Alma Mekanizmalarına Katılımı.json... ✓ Created 22 chunks → 60) Genç Kadınların Karar Alma Mekanizmalarına Katılımı_chunks.jsonl\n",
      "Processing: 61) Youth Policy Implementation at the Local Level- Imereti and Tbilisi.json... ✓ Created 269 chunks → 61) Youth Policy Implementation at the Local Level- Imereti and Tbilisi_chunks.jsonl\n",
      "Processing: 62) TGSP Türkiye_nin Gençleri Yurtdışı Algısı.json... ✓ Created 11 chunks → 62) TGSP Türkiye_nin Gençleri Yurtdışı Algısı_chunks.jsonl\n",
      "Processing: 63) TGSP Türkiye_nin Gençleri Dindarlık Algısı.json... ✓ Created 106 chunks → 63) TGSP Türkiye_nin Gençleri Dindarlık Algısı_chunks.jsonl\n",
      "Processing: 64) TGSP Türkiye_nin Gençleri Yükseköğrenim Algısı.json... ✓ Created 161 chunks → 64) TGSP Türkiye_nin Gençleri Yükseköğrenim Algısı_chunks.jsonl\n",
      "Processing: 65 ) Türkiye Gençlik Araştırması 2023.json... ✓ Created 22 chunks → 65 ) Türkiye Gençlik Araştırması 2023_chunks.jsonl\n",
      "Processing: 66) SODEV Genclik Arastirmasi Raporu 2021.json... ✓ Created 14 chunks → 66) SODEV Genclik Arastirmasi Raporu 2021_chunks.jsonl\n",
      "Processing: 67) SERHAT TRA2 Gençlik Araştırması.json... ✓ Created 825 chunks → 67) SERHAT TRA2 Gençlik Araştırması_chunks.jsonl\n",
      "Processing: 68) İPA İstanbulda Gencligin Demografik ve Sosyoekonomik Profili 20 yillik degisim.json... ✓ Created 229 chunks → 68) İPA İstanbulda Gencligin Demografik ve Sosyoekonomik Profili 20 yillik degisim_chunks.jsonl\n",
      "Processing: 69) İPA Üniversite Mezunu Ev Gençleri Araştırması.json... ✓ Created 10 chunks → 69) İPA Üniversite Mezunu Ev Gençleri Araştırması_chunks.jsonl\n",
      "Processing: 7) eşitsiz demokrasiler.json... ✓ Created 54 chunks → 7) eşitsiz demokrasiler_chunks.jsonl\n",
      "Processing: 70) IPM Türkiye_de Gençlerin Yurtdışında Yaşama İsteği.json... ✓ Created 20 chunks → 70) IPM Türkiye_de Gençlerin Yurtdışında Yaşama İsteği_chunks.jsonl\n",
      "Processing: 71) İPM Türkiye_de Akıllı Kentleşme ve Gençlik Politikaları.json... ✓ Created 37 chunks → 71) İPM Türkiye_de Akıllı Kentleşme ve Gençlik Politikaları_chunks.jsonl\n",
      "Processing: 72) TÜSES Gençlerin Cinsel Sağlık ve Üreme Sağlığı Araştırması.json... ✓ Created 178 chunks → 72) TÜSES Gençlerin Cinsel Sağlık ve Üreme Sağlığı Araştırması_chunks.jsonl\n",
      "Processing: 73) FES Youth Study Southeast Europe .json... ✓ Created 329 chunks → 73) FES Youth Study Southeast Europe _chunks.jsonl\n",
      "Processing: 74) Biarada İstanbul’da Gençlik, Kent Yurttaşlığı ve Yerel Yönetim.json... ✓ Created 196 chunks → 74) Biarada İstanbul’da Gençlik, Kent Yurttaşlığı ve Yerel Yönetim_chunks.jsonl\n",
      "Processing: 75) Türkiye Gençlik Araştırması Özet Bulgular 2023.json... ✓ Created 33 chunks → 75) Türkiye Gençlik Araştırması Özet Bulgular 2023_chunks.jsonl\n",
      "Processing: 76) Toplum Çalışması Enstitüsü Kim Bu Gençler_.json... ✓ Created 16 chunks → 76) Toplum Çalışması Enstitüsü Kim Bu Gençler__chunks.jsonl\n",
      "Processing: 77) KAOS GL LGBTİ+ Öğrenciler.json... ✓ Created 210 chunks → 77) KAOS GL LGBTİ+ Öğrenciler_chunks.jsonl\n",
      "Processing: 78) TOG Üniversiteli Gençlerin İhtiyaçları Araştırması 2024.json... ✓ Created 50 chunks → 78) TOG Üniversiteli Gençlerin İhtiyaçları Araştırması 2024_chunks.jsonl\n",
      "Processing: 79) Haberlerdeki Üniversite 2022.json... ✓ Created 78 chunks → 79) Haberlerdeki Üniversite 2022_chunks.jsonl\n",
      "Processing: 8) genc-oy-strateji-rapor.json... ✓ Created 145 chunks → 8) genc-oy-strateji-rapor_chunks.jsonl\n",
      "Processing: 80) TOG Gençlerin İhtiyaçları Araştırması 2022.json... ✓ Created 18 chunks → 80) TOG Gençlerin İhtiyaçları Araştırması 2022_chunks.jsonl\n",
      "Processing: 81) Yereliz GENÇLİK ALANINDA ÇALIŞAN SİVİL TOPLUM ÖRGÜTLERİ İÇİN YEREL SAVUNUCULUK REHBERİ.json... ✓ Created 1146 chunks → 58) Türkiye_de Gençlik Çalışması ve Politikası_chunks.jsonl\n",
      "Processing: 59) LGBTİ gençler gençlik merkezlerinde ne istiyor_.json... ✓ Created 35 chunks → 59) LGBTİ gençler gençlik merkezlerinde ne istiyor__chunks.jsonl\n",
      "Processing: 6) Sivil Toplum Örgütlerinde Profesyonel ve Gönüllü Çalışma İlişkileri Tehditler Ve Fırsatlar.json... ✓ Created 43 chunks → 6) Sivil Toplum Örgütlerinde Profesyonel ve Gönüllü Çalışma İlişkileri Tehditler Ve Fırsatlar_chunks.jsonl\n",
      "Processing: 60) Genç Kadınların Karar Alma Mekanizmalarına Katılımı.json... ✓ Created 22 chunks → 60) Genç Kadınların Karar Alma Mekanizmalarına Katılımı_chunks.jsonl\n",
      "Processing: 61) Youth Policy Implementation at the Local Level- Imereti and Tbilisi.json... ✓ Created 269 chunks → 61) Youth Policy Implementation at the Local Level- Imereti and Tbilisi_chunks.jsonl\n",
      "Processing: 62) TGSP Türkiye_nin Gençleri Yurtdışı Algısı.json... ✓ Created 11 chunks → 62) TGSP Türkiye_nin Gençleri Yurtdışı Algısı_chunks.jsonl\n",
      "Processing: 63) TGSP Türkiye_nin Gençleri Dindarlık Algısı.json... ✓ Created 106 chunks → 63) TGSP Türkiye_nin Gençleri Dindarlık Algısı_chunks.jsonl\n",
      "Processing: 64) TGSP Türkiye_nin Gençleri Yükseköğrenim Algısı.json... ✓ Created 161 chunks → 64) TGSP Türkiye_nin Gençleri Yükseköğrenim Algısı_chunks.jsonl\n",
      "Processing: 65 ) Türkiye Gençlik Araştırması 2023.json... ✓ Created 22 chunks → 65 ) Türkiye Gençlik Araştırması 2023_chunks.jsonl\n",
      "Processing: 66) SODEV Genclik Arastirmasi Raporu 2021.json... ✓ Created 14 chunks → 66) SODEV Genclik Arastirmasi Raporu 2021_chunks.jsonl\n",
      "Processing: 67) SERHAT TRA2 Gençlik Araştırması.json... ✓ Created 825 chunks → 67) SERHAT TRA2 Gençlik Araştırması_chunks.jsonl\n",
      "Processing: 68) İPA İstanbulda Gencligin Demografik ve Sosyoekonomik Profili 20 yillik degisim.json... ✓ Created 229 chunks → 68) İPA İstanbulda Gencligin Demografik ve Sosyoekonomik Profili 20 yillik degisim_chunks.jsonl\n",
      "Processing: 69) İPA Üniversite Mezunu Ev Gençleri Araştırması.json... ✓ Created 10 chunks → 69) İPA Üniversite Mezunu Ev Gençleri Araştırması_chunks.jsonl\n",
      "Processing: 7) eşitsiz demokrasiler.json... ✓ Created 54 chunks → 7) eşitsiz demokrasiler_chunks.jsonl\n",
      "Processing: 70) IPM Türkiye_de Gençlerin Yurtdışında Yaşama İsteği.json... ✓ Created 20 chunks → 70) IPM Türkiye_de Gençlerin Yurtdışında Yaşama İsteği_chunks.jsonl\n",
      "Processing: 71) İPM Türkiye_de Akıllı Kentleşme ve Gençlik Politikaları.json... ✓ Created 37 chunks → 71) İPM Türkiye_de Akıllı Kentleşme ve Gençlik Politikaları_chunks.jsonl\n",
      "Processing: 72) TÜSES Gençlerin Cinsel Sağlık ve Üreme Sağlığı Araştırması.json... ✓ Created 178 chunks → 72) TÜSES Gençlerin Cinsel Sağlık ve Üreme Sağlığı Araştırması_chunks.jsonl\n",
      "Processing: 73) FES Youth Study Southeast Europe .json... ✓ Created 329 chunks → 73) FES Youth Study Southeast Europe _chunks.jsonl\n",
      "Processing: 74) Biarada İstanbul’da Gençlik, Kent Yurttaşlığı ve Yerel Yönetim.json... ✓ Created 196 chunks → 74) Biarada İstanbul’da Gençlik, Kent Yurttaşlığı ve Yerel Yönetim_chunks.jsonl\n",
      "Processing: 75) Türkiye Gençlik Araştırması Özet Bulgular 2023.json... ✓ Created 33 chunks → 75) Türkiye Gençlik Araştırması Özet Bulgular 2023_chunks.jsonl\n",
      "Processing: 76) Toplum Çalışması Enstitüsü Kim Bu Gençler_.json... ✓ Created 16 chunks → 76) Toplum Çalışması Enstitüsü Kim Bu Gençler__chunks.jsonl\n",
      "Processing: 77) KAOS GL LGBTİ+ Öğrenciler.json... ✓ Created 210 chunks → 77) KAOS GL LGBTİ+ Öğrenciler_chunks.jsonl\n",
      "Processing: 78) TOG Üniversiteli Gençlerin İhtiyaçları Araştırması 2024.json... ✓ Created 50 chunks → 78) TOG Üniversiteli Gençlerin İhtiyaçları Araştırması 2024_chunks.jsonl\n",
      "Processing: 79) Haberlerdeki Üniversite 2022.json... ✓ Created 78 chunks → 79) Haberlerdeki Üniversite 2022_chunks.jsonl\n",
      "Processing: 8) genc-oy-strateji-rapor.json... ✓ Created 145 chunks → 8) genc-oy-strateji-rapor_chunks.jsonl\n",
      "Processing: 80) TOG Gençlerin İhtiyaçları Araştırması 2022.json... ✓ Created 18 chunks → 80) TOG Gençlerin İhtiyaçları Araştırması 2022_chunks.jsonl\n",
      "Processing: 81) Yereliz GENÇLİK ALANINDA ÇALIŞAN SİVİL TOPLUM ÖRGÜTLERİ İÇİN YEREL SAVUNUCULUK REHBERİ.json... ✓ Created 66 chunks → 81) Yereliz GENÇLİK ALANINDA ÇALIŞAN SİVİL TOPLUM ÖRGÜTLERİ İÇİN YEREL SAVUNUCULUK REHBERİ_chunks.jsonl\n",
      "Processing: 82) KONDA Barometre 2024.json... ✓ Created 41 chunks → 82) KONDA Barometre 2024_chunks.jsonl\n",
      "Processing: 83) OECD Youth Policy Toolkit.json... ✓ Created 618 chunks → 83) OECD Youth Policy Toolkit_chunks.jsonl\n",
      "Processing: 84) TİP_li Öğrenciler Barınma Raporu 2023.json... ✓ Created 100 chunks → 84) TİP_li Öğrenciler Barınma Raporu 2023_chunks.jsonl\n",
      "Processing: 85) ILO Global Employement Trends for Youth 2020.json... ✓ Created 468 chunks → 85) ILO Global Employement Trends for Youth 2020_chunks.jsonl\n",
      "Processing: 86) GoFor Hangi Genç_.json... ✓ Created 97 chunks → 86) GoFor Hangi Genç__chunks.jsonl\n",
      "Processing: 87) GoFor 2023 Universiteler icin Uzaktan Egitim ve KYK Yurtlarindan Ogrencilerin Cikarilmasina Iliskin Kararlar Hakkinda Bilgi Notu.json... ✓ Created 15 chunks → 87) GoFor 2023 Universiteler icin Uzaktan Egitim ve KYK Yurtlarindan Ogrencilerin Cikarilmasina Iliskin Kararlar Hakkinda Bilgi Notu_chunks.jsonl\n",
      "Processing: 88) Türkiye_de NEET Üzerine Yapılmış Çalışmalara İlişkin Bir Değerlendirme 2024.json... ✓ Created 71 chunks → 88) Türkiye_de NEET Üzerine Yapılmış Çalışmalara İlişkin Bir Değerlendirme 2024_chunks.jsonl\n",
      "Processing: 89) UNFPA İstatisliklerle Gençlik.json... ✓ Created 1 chunks → 89) UNFPA İstatisliklerle Gençlik_chunks.jsonl\n",
      "Processing: 9) Politik Karar Verme Süreçlerine Etkili ve Anlamlı KATILIM HAKKI ve MEKANİZMALAR.json... ✓ Created 275 chunks → 9) Politik Karar Verme Süreçlerine Etkili ve Anlamlı KATILIM HAKKI ve MEKANİZMALAR_chunks.jsonl\n",
      "Processing: 90) FES Genclerin Gözünden Dindar-Seküler Eksenli Kutuplaşma.json... ✓ Created 453 chunks → 90) FES Genclerin Gözünden Dindar-Seküler Eksenli Kutuplaşma_chunks.jsonl\n",
      "Processing: 91) Veriler.json... ✓ Created 19 chunks → 91) Veriler_chunks.jsonl\n",
      "\n",
      "Processing complete!\n",
      "Total chunks created: 14606\n",
      "Files saved to: C:\\Users\\yigit\\Desktop\\Enterprises\\arayuz-9\\basic-chunks\n",
      "✓ Created 66 chunks → 81) Yereliz GENÇLİK ALANINDA ÇALIŞAN SİVİL TOPLUM ÖRGÜTLERİ İÇİN YEREL SAVUNUCULUK REHBERİ_chunks.jsonl\n",
      "Processing: 82) KONDA Barometre 2024.json... ✓ Created 41 chunks → 82) KONDA Barometre 2024_chunks.jsonl\n",
      "Processing: 83) OECD Youth Policy Toolkit.json... ✓ Created 618 chunks → 83) OECD Youth Policy Toolkit_chunks.jsonl\n",
      "Processing: 84) TİP_li Öğrenciler Barınma Raporu 2023.json... ✓ Created 100 chunks → 84) TİP_li Öğrenciler Barınma Raporu 2023_chunks.jsonl\n",
      "Processing: 85) ILO Global Employement Trends for Youth 2020.json... ✓ Created 468 chunks → 85) ILO Global Employement Trends for Youth 2020_chunks.jsonl\n",
      "Processing: 86) GoFor Hangi Genç_.json... ✓ Created 97 chunks → 86) GoFor Hangi Genç__chunks.jsonl\n",
      "Processing: 87) GoFor 2023 Universiteler icin Uzaktan Egitim ve KYK Yurtlarindan Ogrencilerin Cikarilmasina Iliskin Kararlar Hakkinda Bilgi Notu.json... ✓ Created 15 chunks → 87) GoFor 2023 Universiteler icin Uzaktan Egitim ve KYK Yurtlarindan Ogrencilerin Cikarilmasina Iliskin Kararlar Hakkinda Bilgi Notu_chunks.jsonl\n",
      "Processing: 88) Türkiye_de NEET Üzerine Yapılmış Çalışmalara İlişkin Bir Değerlendirme 2024.json... ✓ Created 71 chunks → 88) Türkiye_de NEET Üzerine Yapılmış Çalışmalara İlişkin Bir Değerlendirme 2024_chunks.jsonl\n",
      "Processing: 89) UNFPA İstatisliklerle Gençlik.json... ✓ Created 1 chunks → 89) UNFPA İstatisliklerle Gençlik_chunks.jsonl\n",
      "Processing: 9) Politik Karar Verme Süreçlerine Etkili ve Anlamlı KATILIM HAKKI ve MEKANİZMALAR.json... ✓ Created 275 chunks → 9) Politik Karar Verme Süreçlerine Etkili ve Anlamlı KATILIM HAKKI ve MEKANİZMALAR_chunks.jsonl\n",
      "Processing: 90) FES Genclerin Gözünden Dindar-Seküler Eksenli Kutuplaşma.json... ✓ Created 453 chunks → 90) FES Genclerin Gözünden Dindar-Seküler Eksenli Kutuplaşma_chunks.jsonl\n",
      "Processing: 91) Veriler.json... ✓ Created 19 chunks → 91) Veriler_chunks.jsonl\n",
      "\n",
      "Processing complete!\n",
      "Total chunks created: 14606\n",
      "Files saved to: C:\\Users\\yigit\\Desktop\\Enterprises\\arayuz-9\\basic-chunks\n"
     ]
    }
   ],
   "source": [
    "# Run the chunker\n",
    "if __name__ == \"__main__\":\n",
    "    # Process all JSON files and create chunks\n",
    "    process_all_json_files(max_chunk_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43978d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d33674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED VERSION - Much faster overlap chunking\n",
    "from collections import deque\n",
    "\n",
    "def chunk_by_paragraphs_optimized(text: str, max_chunk_size: int = 1000, overlap_ratio: float = 0.1) -> List[str]:\n",
    "    \"\"\"\n",
    "    Optimized version: Split text into chunks by paragraphs with overlap.\n",
    "    Uses sliding window approach instead of list insertions for O(n) complexity.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        max_chunk_size: Maximum characters per chunk\n",
    "        overlap_ratio: Fraction of chunk to overlap (default 0.1 = 10%)\n",
    "        \n",
    "    Returns:\n",
    "        List of text chunks with overlap\n",
    "    \"\"\"\n",
    "    # Split by double newlines (paragraphs)\n",
    "    paragraphs = [para.strip() for para in text.split('\\n\\n') if para.strip()]\n",
    "    \n",
    "    if not paragraphs:\n",
    "        return []\n",
    "    \n",
    "    chunks = []\n",
    "    overlap_size = int(max_chunk_size * overlap_ratio)\n",
    "    \n",
    "    # Pre-calculate paragraph lengths to avoid repeated len() calls\n",
    "    para_lengths = [len(para) for para in paragraphs]\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(paragraphs):\n",
    "        current_chunk_paras = []\n",
    "        current_length = 0\n",
    "        start_idx = i\n",
    "        \n",
    "        # Build current chunk\n",
    "        while i < len(paragraphs) and current_length + para_lengths[i] <= max_chunk_size:\n",
    "            current_chunk_paras.append(paragraphs[i])\n",
    "            current_length += para_lengths[i]\n",
    "            i += 1\n",
    "        \n",
    "        # Handle oversized single paragraph\n",
    "        if not current_chunk_paras and i < len(paragraphs):\n",
    "            oversized_para = paragraphs[i]\n",
    "            sentence_chunks = _split_oversized_paragraph_optimized(oversized_para, max_chunk_size, overlap_size)\n",
    "            chunks.extend(sentence_chunks)\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        if current_chunk_paras:\n",
    "            chunk_text = '\\n\\n'.join(current_chunk_paras)\n",
    "            chunks.append(chunk_text)\n",
    "            \n",
    "            # Calculate overlap for next chunk using sliding window\n",
    "            if i < len(paragraphs):\n",
    "                overlap_start = _find_overlap_start_optimized(\n",
    "                    current_chunk_paras, para_lengths[start_idx:i], overlap_size\n",
    "                )\n",
    "                if overlap_start is not None:\n",
    "                    i = start_idx + overlap_start  # Slide back to overlap position\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def _split_oversized_paragraph_optimized(para: str, max_chunk_size: int, overlap_size: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Optimized helper to split oversized paragraphs into sentences with overlap.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
    "    sentence_lengths = [len(sent) for sent in sentences]\n",
    "    \n",
    "    chunks = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(sentences):\n",
    "        current_sentences = []\n",
    "        current_length = 0\n",
    "        start_idx = i\n",
    "        \n",
    "        # Build sentence chunk\n",
    "        while i < len(sentences) and current_length + sentence_lengths[i] <= max_chunk_size:\n",
    "            current_sentences.append(sentences[i])\n",
    "            current_length += sentence_lengths[i]\n",
    "            i += 1\n",
    "        \n",
    "        if current_sentences:\n",
    "            chunks.append(' '.join(current_sentences))\n",
    "            \n",
    "            # Calculate sentence-level overlap\n",
    "            if i < len(sentences):\n",
    "                overlap_start = _find_sentence_overlap_start(\n",
    "                    current_sentences, sentence_lengths[start_idx:i], overlap_size\n",
    "                )\n",
    "                if overlap_start is not None:\n",
    "                    i = start_idx + overlap_start\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def _find_overlap_start_optimized(paragraphs: List[str], lengths: List[int], target_overlap: int) -> int:\n",
    "    \"\"\"\n",
    "    Find the starting index for overlap using reverse accumulation.\n",
    "    Returns the paragraph index to start the next chunk from.\n",
    "    \"\"\"\n",
    "    if not paragraphs or target_overlap <= 0:\n",
    "        return None\n",
    "    \n",
    "    accumulated_length = 0\n",
    "    \n",
    "    # Work backwards from the end\n",
    "    for i in range(len(paragraphs) - 1, -1, -1):\n",
    "        if accumulated_length + lengths[i] <= target_overlap:\n",
    "            accumulated_length += lengths[i]\n",
    "        else:\n",
    "            # If we can't fit the whole paragraph, check if we can fit part of it\n",
    "            remaining_space = target_overlap - accumulated_length\n",
    "            if remaining_space > 50:  # Minimum meaningful overlap\n",
    "                return i  # Start from this paragraph (will be partially included)\n",
    "            elif i < len(paragraphs) - 1:\n",
    "                return i + 1  # Start from next paragraph\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    return 0 if accumulated_length > 0 else None\n",
    "\n",
    "\n",
    "def _find_sentence_overlap_start(sentences: List[str], lengths: List[int], target_overlap: int) -> int:\n",
    "    \"\"\"\n",
    "    Find the starting sentence index for overlap.\n",
    "    \"\"\"\n",
    "    if not sentences or target_overlap <= 0:\n",
    "        return None\n",
    "    \n",
    "    accumulated_length = 0\n",
    "    \n",
    "    for i in range(len(sentences) - 1, -1, -1):\n",
    "        if accumulated_length + lengths[i] <= target_overlap:\n",
    "            accumulated_length += lengths[i]\n",
    "        else:\n",
    "            return i + 1 if i < len(sentences) - 1 else None\n",
    "    \n",
    "    return 0 if accumulated_length > 0 else None\n",
    "\n",
    "\n",
    "# Optimized processing functions\n",
    "def process_json_file_optimized(json_path: Path, max_chunk_size: int = 1000, overlap_ratio: float = 0.1) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Optimized version of process_json_file.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    text = data.get('text', '')\n",
    "    metadata = data.get('metadata', {})\n",
    "    \n",
    "    # Use optimized chunking\n",
    "    chunks = chunk_by_paragraphs_optimized(text, max_chunk_size, overlap_ratio)\n",
    "    \n",
    "    # Pre-allocate result list for better performance\n",
    "    result = []\n",
    "    for i, chunk_text in enumerate(chunks):\n",
    "        # Cache split for word count to avoid repeated splitting\n",
    "        words = chunk_text.split()\n",
    "        result.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"text\": chunk_text,\n",
    "            \"char_count\": len(chunk_text),\n",
    "            \"word_count\": len(words),\n",
    "            \"source_file\": metadata.get('source_file', ''),\n",
    "            \"source_path\": metadata.get('source_path', '')\n",
    "        })\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def process_all_json_files_optimized(\n",
    "    input_dir: str = r\"C:\\Users\\yigit\\Desktop\\Enterprises\\polcon\\text\",\n",
    "    output_dir: str = r\"C:\\Users\\yigit\\Desktop\\Enterprises\\polcon\\basic-chunks\",\n",
    "    max_chunk_size: int = 1000,\n",
    "    overlap_ratio: float = 0.1\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Optimized version with better performance and memory usage.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Find all JSON files\n",
    "    json_files = list(input_path.glob(\"*.json\"))\n",
    "    \n",
    "    if not json_files:\n",
    "        print(f\"No JSON files found in {input_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(json_files)} JSON files to process\")\n",
    "    print(f\"Chunk size: {max_chunk_size}, Overlap: {overlap_ratio*100:.1f}%\\n\")\n",
    "    \n",
    "    total_chunks = 0\n",
    "    \n",
    "    # Process each JSON file\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            print(f\"Processing: {json_file.name}...\", end=\" \")\n",
    "            \n",
    "            # Use optimized processing\n",
    "            chunks = process_json_file_optimized(json_file, max_chunk_size, overlap_ratio)\n",
    "            \n",
    "            # Save as JSONL\n",
    "            output_file = output_path / f\"{json_file.stem}_chunks.jsonl\"\n",
    "            save_chunks_jsonl(chunks, output_file)\n",
    "            \n",
    "            total_chunks += len(chunks)\n",
    "            print(f\"✓ {len(chunks)} chunks → {output_file.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "    \n",
    "    print(f\"\\n🎉 Processing complete!\")\n",
    "    print(f\"📊 Total chunks created: {total_chunks}\")\n",
    "    print(f\"💾 Files saved to: {output_dir}\")\n",
    "\n",
    "\n",
    "# Performance comparison function\n",
    "def compare_performance():\n",
    "    \"\"\"\n",
    "    Compare performance between original and optimized versions.\n",
    "    \"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Sample text for testing\n",
    "    sample_text = \"\"\"\n",
    "    This is a sample paragraph for testing purposes. It contains multiple sentences to simulate real document processing.\n",
    "    \n",
    "    This is another paragraph that we'll use to test the chunking algorithms. We want to see how they handle overlapping content.\n",
    "    \n",
    "    The third paragraph adds more content to make the test more realistic. Performance differences should become apparent with larger texts.\n",
    "    \n",
    "    Final paragraph to complete our sample text. This should be enough content to demonstrate the algorithmic differences.\n",
    "    \"\"\" * 50  # Multiply to make it larger\n",
    "    \n",
    "    print(\"🔍 Performance Comparison Test\")\n",
    "    print(f\"Sample text length: {len(sample_text)} characters\\n\")\n",
    "    \n",
    "    # Test original version\n",
    "    start_time = time.time()\n",
    "    chunks_original = chunk_by_paragraphs(sample_text, max_chunk_size=1000, overlap_ratio=0.1)\n",
    "    original_time = time.time() - start_time\n",
    "    \n",
    "    # Test optimized version\n",
    "    start_time = time.time()\n",
    "    chunks_optimized = chunk_by_paragraphs_optimized(sample_text, max_chunk_size=1000, overlap_ratio=0.1)\n",
    "    optimized_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"⏱️  Original algorithm: {original_time:.4f} seconds\")\n",
    "    print(f\"⚡ Optimized algorithm: {optimized_time:.4f} seconds\")\n",
    "    print(f\"🚀 Speed improvement: {original_time/optimized_time:.1f}x faster\")\n",
    "    print(f\"📈 Original chunks: {len(chunks_original)}\")\n",
    "    print(f\"📈 Optimized chunks: {len(chunks_optimized)}\")\n",
    "    \n",
    "    return chunks_original, chunks_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7046af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run performance comparison\n",
    "print(\"Running performance comparison...\")\n",
    "original_chunks, optimized_chunks = compare_performance()\n",
    "\n",
    "# Verify both produce similar results\n",
    "print(f\"\\n✅ Verification:\")\n",
    "print(f\"Both algorithms produced same number of chunks: {len(original_chunks) == len(optimized_chunks)}\")\n",
    "\n",
    "# Show sample chunks to verify overlap is working\n",
    "if len(optimized_chunks) >= 2:\n",
    "    print(f\"\\n📝 Sample overlap verification:\")\n",
    "    chunk1_end = optimized_chunks[0][-100:]  # Last 100 chars of first chunk\n",
    "    chunk2_start = optimized_chunks[1][:100]  # First 100 chars of second chunk\n",
    "    \n",
    "    # Simple overlap check\n",
    "    words1 = set(chunk1_end.split())\n",
    "    words2 = set(chunk2_start.split())\n",
    "    overlap_words = words1.intersection(words2)\n",
    "    print(f\"Common words between chunks: {len(overlap_words)} words\")\n",
    "    print(f\"Overlap detected: {len(overlap_words) > 0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb6a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Running OPTIMIZED chunking with overlap...\n",
      "Found 89 JSON files to process\n",
      "Chunk size: 1000, Overlap: 10.0%\n",
      "\n",
      "Processing: 1) Temel kavramlar önyargı, kalıpyargı ve ayrımcılık.json... ✓ 35 chunks → 1) Temel kavramlar önyargı, kalıpyargı ve ayrımcılık_chunks.jsonl\n",
      "Processing: 10) TÜRKİYE’DE ÖRGÜTLENME ÖZGÜRLÜĞÜNÜN GENEL GÖRÜNÜMÜ-II .json... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use the OPTIMIZED version for production processing\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This should be 3-5x faster than the original implementation\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 Running OPTIMIZED chunking with overlap...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mprocess_all_json_files_optimized\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_chunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moverlap_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 10% overlap\u001b[39;49;00m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Alternative: Use different overlap ratios for experimentation\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# process_all_json_files_optimized(max_chunk_size=1000, overlap_ratio=0.05)  # 5% overlap\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# process_all_json_files_optimized(max_chunk_size=1000, overlap_ratio=0.15)  # 15% overlap\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mprocess_all_json_files_optimized\u001b[39m\u001b[34m(input_dir, output_dir, max_chunk_size, overlap_ratio)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# Use optimized processing\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m chunks = \u001b[43mprocess_json_file_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Save as JSONL\u001b[39;00m\n\u001b[32m    211\u001b[39m output_file = output_path / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson_file.stem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_chunks.jsonl\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 156\u001b[39m, in \u001b[36mprocess_json_file_optimized\u001b[39m\u001b[34m(json_path, max_chunk_size, overlap_ratio)\u001b[39m\n\u001b[32m    153\u001b[39m metadata = data.get(\u001b[33m'\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Use optimized chunking\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m chunks = \u001b[43mchunk_by_paragraphs_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_ratio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[38;5;66;03m# Pre-allocate result list for better performance\u001b[39;00m\n\u001b[32m    159\u001b[39m result = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mchunk_by_paragraphs_optimized\u001b[39m\u001b[34m(text, max_chunk_size, overlap_ratio)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m current_chunk_paras \u001b[38;5;129;01mand\u001b[39;00m i < \u001b[38;5;28mlen\u001b[39m(paragraphs):\n\u001b[32m     43\u001b[39m     oversized_para = paragraphs[i]\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     sentence_chunks = \u001b[43m_split_oversized_paragraph_optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43moversized_para\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_chunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlap_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     chunks.extend(sentence_chunks)\n\u001b[32m     46\u001b[39m     i += \u001b[32m1\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36m_split_oversized_paragraph_optimized\u001b[39m\u001b[34m(para, max_chunk_size, overlap_size)\u001b[39m\n\u001b[32m     71\u001b[39m chunks = []\n\u001b[32m     72\u001b[39m i = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m i < \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     75\u001b[39m     current_sentences = []\n\u001b[32m     76\u001b[39m     current_length = \u001b[32m0\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Use the OPTIMIZED version for production processing\n",
    "# This should be 3-5x faster than the original implementation\n",
    "\n",
    "print(\"🚀 Running OPTIMIZED chunking with overlap...\")\n",
    "process_all_json_files_optimized(\n",
    "    max_chunk_size=1000, \n",
    "    overlap_ratio=0.1  # 10% overlap\n",
    ")\n",
    "\n",
    "# Alternative: Use different overlap ratios for experimentation\n",
    "# process_all_json_files_optimized(max_chunk_size=1000, overlap_ratio=0.05)  # 5% overlap\n",
    "# process_all_json_files_optimized(max_chunk_size=1000, overlap_ratio=0.15)  # 15% overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a033634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
